#!/usr/bin/env python
"""
main.py â€“ VOCABå°‚ç”¨ç‰ˆï¼ˆå˜ç´”çµåˆï¼‹æ—¥æœ¬èªãµã‚ŠãŒãª[TTSã®ã¿]ï¼‹å…ˆé ­ç„¡éŸ³ï¼‹æœ€çŸ­1ç§’ï¼‰
"""

import argparse, logging, re, json, subprocess, os
from datetime import datetime
from pathlib import Path
from shutil import rmtree

import yaml
from pydub import AudioSegment
from openai import OpenAI

from config         import BASE, OUTPUT, TEMP
from translate      import translate
from tts_openai     import speak
from audio_fx       import enhance
from bg_image       import fetch as fetch_bg
from thumbnail      import make_thumbnail
from upload_youtube import upload
from topic_picker   import pick_by_content_type

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GPT = OpenAI()
CONTENT_MODE = "vocab"
DEBUG_SCRIPT = os.getenv("DEBUG_SCRIPT", "0") == "1"
GAP_MS       = int(os.getenv("GAP_MS", "120"))
PRE_SIL_MS   = int(os.getenv("PRE_SIL_MS", "120"))
MIN_UTTER_MS = int(os.getenv("MIN_UTTER_MS", "1000"))

# ç”Ÿæˆæ¸©åº¦ï¼ˆç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯ï¼‰: ä½æ¸©ã§å®‰å®šå¯„ã‚Š
EX_TEMP   = float(os.getenv("EX_TEMP", "0.25"))   # ä¾‹æ–‡
LIST_TEMP = float(os.getenv("LIST_TEMP", "0.25")) # èªå½™ãƒªã‚¹ãƒˆ

LANG_NAME = {
    "en": "English", "pt": "Portuguese", "id": "Indonesian",
    "ja": "Japanese","ko": "Korean", "es": "Spanish",
}

JP_CONV_LABEL = {
    "en": "è‹±ä¼šè©±", "ja": "æ—¥æœ¬èªä¼šè©±", "es": "ã‚¹ãƒšã‚¤ãƒ³èªä¼šè©±",
    "pt": "ãƒãƒ«ãƒˆã‚¬ãƒ«èªä¼šè©±", "ko": "éŸ“å›½èªä¼šè©±", "id": "ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èªä¼šè©±",
}

with open(BASE / "combos.yaml", encoding="utf-8") as f:
    COMBOS = yaml.safe_load(f)["combos"]

def reset_temp():
    if TEMP.exists():
        rmtree(TEMP)
    TEMP.mkdir(exist_ok=True)

def sanitize_title(raw: str) -> str:
    title = re.sub(r"^\s*(?:\d+\s*[.)]|[-â€¢ãƒ»])\s*", "", raw)
    title = re.sub(r"[\s\u3000]+", " ", title).strip()
    return title[:97] + "â€¦" if len(title) > 100 else title or "Auto Video"

def _infer_title_lang(audio_lang: str, subs: list[str], combo: dict) -> str:
    if "title_lang" in combo and combo["title_lang"]:
        return combo["title_lang"]
    if len(subs) >= 2:
        return subs[1]
    for s in subs:
        if s != audio_lang:
            return s
    return audio_lang

def resolve_topic(arg_topic: str) -> str:
    if arg_topic and arg_topic.strip().lower() == "auto":
        first_audio_lang = COMBOS[0]["audio"]
        topic = pick_by_content_type("vocab", first_audio_lang)
        logging.info(f"[AUTO VOCAB THEME] {topic}")
        return topic
    return arg_topic

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä¾‹æ–‡ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— & æ¤œè¨¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_URL_RE    = re.compile(r"https?://\S+")
_NUM_LEAD  = re.compile(r"^\s*\d+[\).:\-]\s*")
_QUOTES    = re.compile(r'^[\"â€œâ€\']+|[\"â€œâ€\']+$')
_EMOJI_RE  = re.compile(r"[\U00010000-\U0010ffff]")  # ãŠãŠã¾ã‹ãªçµµæ–‡å­—
_ASCII_LET = re.compile(r"[A-Za-z]+")

def _normalize_spaces(t: str) -> str:
    return re.sub(r"\s+", " ", t or "").strip()

def _clean_example_common(text: str) -> str:
    t = (text or "").strip()
    t = _URL_RE.sub("", t)
    t = _NUM_LEAD.sub("", t)
    t = _QUOTES.sub("", t)
    t = _EMOJI_RE.sub("", t)
    t = re.sub(r"[\:\-â€“â€”]\s*$", "", t)  # è¡Œæœ«ã®è¨˜å·ã ã¾ã‚Š
    return _normalize_spaces(t)

# CJKç‡ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¥æœ¬èªã®ä¸€è²«æ€§æ‹…ä¿ï¼‰
_CJK_RE = re.compile(r"[\u3040-\u30FF\u4E00-\u9FFF\u3000-\u303F]")  # ã²ã‚‰ãŒãªãƒ»ã‚«ã‚¿ã‚«ãƒŠãƒ»æ¼¢å­—ãƒ»å¥èª­ç‚¹ç­‰

def _cjk_ratio(s: str) -> float:
    if not s:
        return 0.0
    cjk = len(_CJK_RE.findall(s))
    return cjk / max(len(s), 1)

def _ensure_period_for_sentence(txt: str, lang_code: str) -> str:
    if re.search(r"[ã€‚.!?ï¼ï¼Ÿ]$", txt or ""):
        return txt
    return (txt or "") + ("ã€‚" if lang_code == "ja" else ".")

def _is_single_sentence(text: str) -> bool:
    # çµ‚æ­¢è¨˜å·ãŒ2å€‹ä»¥ä¸Šã‚ã‚‹ãªã‚‰è¤‡æ–‡ã£ã½ã„ã¨ã¿ãªã™
    return len(re.findall(r"[ã€‚.!?ï¼ï¼Ÿ]", text or "")) <= 1

def _fits_length(text: str, lang_code: str) -> bool:
    if lang_code in ("ja", "ko", "zh"):
        return len(text or "") <= 24   # ä»¥å‰ã‚ˆã‚Šå°‘ã—çŸ­ã‚ã§å®‰å®š
    # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆç³»ï¼šå˜èªæ•°12ä»¥ä¸‹
    return len(re.findall(r"\b\w+\b", text or "")) <= 12

def _postprocess_example(text: str, lang_code: str) -> str:
    """
    ç”Ÿæˆç›´å¾Œã«â€œå­—å¹•ç”¨ã®æ­£è¦åŒ–æ¸ˆã¿æœ¬æ–‡â€ã‚’ä½œã‚‹ã€‚
    ã“ã“ã§å®‰å®šã•ã›ãŸã‚‚ã®ã‚’å°æœ¬ã«æ¡ç”¨ã™ã‚‹ï¼ˆï¼TTS/å­—å¹•ã®ç´ ã«ãªã‚‹ï¼‰ã€‚
    """
    t = _clean_example_common(text)

    if lang_code == "ja":
        # ãƒ­ãƒ¼ãƒå­—/è‹±å˜èªã¯å‰Šã‚‹ï¼ˆæ•°å­—ã¯ä¿æŒï¼‰
        t = _ASCII_LET.sub("", t)
        # ä¸‰ç‚¹ãƒªãƒ¼ãƒ€ã®çµ±ä¸€
        t = t.replace("...", "ã€‚").replace("â€¦", "ã€‚")
        # ä½™åˆ†ãªç©ºç™½
        t = _normalize_spaces(t)
        # CJKç‡ãŒä½ã„ï¼æ··åœ¨ãŒå¤šã„ â†’ ç ´æ£„
        if _cjk_ratio(t) < 0.8:
            t = ""
    # æœ€çµ‚ãƒã‚§ãƒƒã‚¯
    if not t:
        return t
    if not _is_single_sentence(t) or not _fits_length(t, lang_code):
        return ""
    return _ensure_period_for_sentence(t, lang_code)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# èªå½™ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _gen_example_sentence(word: str, lang_code: str) -> str:
    """
    1æ–‡ã ã‘ç”Ÿæˆã€‚æ¤œè¨¼NGãªã‚‰æœ€å¤§3å›ãƒªãƒˆãƒ©ã‚¤ã€‚å¤±æ•—æ™‚ã¯ãƒ•ã‚§ãƒ¼ãƒ«ã‚»ãƒ¼ãƒ•ã€‚
    å°æœ¬ã«è¼‰ã›ã‚‹ã®ã¯â€œãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ã‚¹æ¸ˆã¿â€ã®æ–‡ã€‚
    """
    system = {
        "role": "system",
        "content": (
            "You write a single, natural sentence. "
            "Output exactly one sentence. No quotes, no lists, no emojis, no URLs."
        ),
    }
    user_tpl = (
        "Write exactly one short, natural sentence in {lang} that uses the word: {w}. "
        "Keep it monolingual and plain (no brackets or glosses). "
        "Length guide: <=12 words for alphabetic languages; concise for CJK. "
        "Return ONLY the sentence."
    )
    lang_name = LANG_NAME.get(lang_code, "English")
    prompt = user_tpl.format(lang=lang_name, w=word)

    for _ in range(3):
        raw = ""
        try:
            rsp = GPT.chat.completions.create(
                model="gpt-4o-mini",
                messages=[system, {"role":"user","content":prompt}],
                temperature=EX_TEMP,
                top_p=1.0,
                presence_penalty=0,
                frequency_penalty=0,
            )
            raw = (rsp.choices[0].message.content or "").strip()
        except Exception:
            raw = ""

        cand = _postprocess_example(raw, lang_code)

        # å˜èªã‚’å«ã‚€ã‹ï¼ˆCJKã¯ç´ ç›´ã«ä¸€è‡´ï¼‰
        try:
            contains_word = (word.lower() in cand.lower()) if lang_code not in ("ja","ko","zh") else (word in cand)
        except Exception:
            contains_word = True

        if cand and contains_word:
            return cand

    # ãƒ•ã‚§ãƒ¼ãƒ«ã‚»ãƒ¼ãƒ•
    if lang_code == "ja":
        return _ensure_period_for_sentence(f"{word} ã‚’ä½¿ã£ã¦ã¿ã‚ˆã†", lang_code)
    else:
        return _ensure_period_for_sentence(f"Let's practice {word}", lang_code)

def _gen_vocab_list(theme: str, lang_code: str, n: int) -> list[str]:
    theme_for_prompt = translate(theme, lang_code) if lang_code != "en" else theme
    prompt = (
        f"List {n} essential single or hyphenated words for {theme_for_prompt} context "
        f"in {LANG_NAME.get(lang_code,'English')}. Return ONLY one word per line, no numbering."
    )
    content = ""
    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"user","content":prompt}],
            temperature=LIST_TEMP,
            top_p=1.0,
            presence_penalty=0,
            frequency_penalty=0,
        )
        content = (rsp.choices[0].message.content or "")
    except Exception:
        content = ""

    # 1è¡Œ1èªã«æ­£è¦åŒ–ï¼ˆé‡è¤‡é™¤å»ï¼‰ã€‚ãƒã‚¤ãƒ•ãƒ³èªã¯è¨±å¯ã€‚
    words = []
    for line in content.splitlines():
        w = (line or "").strip()
        if not w:
            continue
        w = re.sub(r"^\d+[\).]?\s*", "", w)   # è¡Œé ­ç•ªå·
        w = re.sub(r"[ï¼Œã€ã€‚.!?ï¼ï¼Ÿ]+$", "", w)  # æœ«å°¾å¥èª­ç‚¹
        # ã‚«ãƒ³ãƒ/ã‚»ãƒŸã‚³ãƒ­ãƒ³/ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ ã§åˆ†å‰²ã—ã€å…ˆé ­ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¡ç”¨
        w = re.split(r"[,\;/\t ]+", w)[0]
        if w and w not in words:
            words.append(w)

    if len(words) >= n:
        return words[:n]

    fallback = ["check-in", "reservation", "checkout", "receipt", "elevator", "lobby", "upgrade"]
    return fallback[:n]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ—¥æœ¬èªTTSç”¨ãµã‚ŠãŒãª
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_KANJI_ONLY = re.compile(r"^[ä¸€-é¾¥ã€…]+$")
_PARENS_JA  = re.compile(r"\s*[\(\ï¼ˆ][^)\ï¼‰]{1,40}[\)\ï¼‰]\s*")

def _kana_reading(word: str) -> str:
    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role":"user",
                "content":(
                    "æ¬¡ã®æ—¥æœ¬èªå˜èªã®èª­ã¿ã‚’ã²ã‚‰ãŒãªã ã‘ã§1èªè¿”ã—ã¦ãã ã•ã„ã€‚"
                    "è¨˜å·ãƒ»æ‹¬å¼§ãƒ»èª¬æ˜ã¯ä¸è¦ã€‚\n"
                    f"å˜èª: {word}"
                )
            }],
            temperature=0.0,  # æ±ºå®šè«–
            top_p=1.0,
            presence_penalty=0,
            frequency_penalty=0,
        )
        yomi = (rsp.choices[0].message.content or "").strip()
        yomi = re.sub(r"[^ã-ã‚–ã‚ã‚ãƒ¼]+", "", yomi)
        return yomi[:20]
    except Exception:
        return ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¿ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«è¨€èªã«çµ±ä¸€ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_title(theme, title_lang: str, audio_lang_for_label: str | None = None):
    if title_lang not in LANG_NAME:
        title_lang = "en"
    try:
        theme_local = theme if title_lang == "en" else translate(theme, title_lang)
    except Exception:
        theme_local = theme

    if title_lang == "ja":
        base = f"{theme_local} ã§ä½¿ãˆã‚‹ä¸€è¨€"
        label = JP_CONV_LABEL.get(audio_lang_for_label or "", "")
        t = f"{label} {base}" if label and label not in base else base
        return sanitize_title(t)[:28]
    else:
        if title_lang == "en":
            t = f"{theme_local.capitalize()} vocab in one minute"
        else:
            t = f"{theme_local} vocabulary"
        return sanitize_title(t)[:55]

def make_desc(theme, title_lang: str):
    if title_lang not in LANG_NAME:
        title_lang = "en"
    try:
        theme_local = theme if title_lang == "en" else translate(theme, title_lang)
    except Exception:
        theme_local = theme

    msg = {
        "ja": f"{theme_local} ã«å¿…é ˆã®èªå½™ã‚’çŸ­æ™‚é–“ã§ãƒã‚§ãƒƒã‚¯ã€‚å£°ã«å‡ºã—ã¦ä¸€ç·’ã«ç·´ç¿’ã—ã‚ˆã†ï¼ #vocab #learning",
        "en": f"Quick practice for {theme_local} vocabulary. Repeat after the audio! #vocab #learning",
        "pt": f"Pratique rÃ¡pido o vocabulÃ¡rio de {theme_local}. Repita em voz alta! #vocab #aprendizado",
        "es": f"PrÃ¡ctica rÃ¡pida de vocabulario de {theme_local}. Â¡Repite en voz alta! #vocab #aprendizaje",
        "ko": f"{theme_local} ì–´íœ˜ë¥¼ ë¹ ë¥´ê²Œ ì—°ìŠµí•˜ì„¸ìš”. ì†Œë¦¬ ë‚´ì–´ ë”°ë¼ ë§í•´ìš”! #vocab #learning",
        "id": f"Latihan cepat kosakata {theme_local}. Ucapkan keras-keras! #vocab #belajar",
    }
    return msg.get(title_lang, msg["en"])

def make_tags(theme, audio_lang, subs, title_lang):
    tags = [
        theme, "vocabulary", "language learning", "speaking practice",
        "listening practice", "subtitles"
    ]
    for code in subs:
        if code in LANG_NAME:
            tags.append(f"{LANG_NAME[code]} subtitles")
    seen, out = set(), []
    for t in tags:
        if t not in seen:
            seen.add(t); out.append(t)
    return out[:15]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å˜ç´”çµåˆï¼ˆWAVä¸­é–“ãƒ»è¡Œé ­ç„¡éŸ³ãƒ»æœ€çŸ­å°ºãƒ»è¡Œé–“ã‚®ãƒ£ãƒƒãƒ—ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _concat_with_gaps(audio_paths, gap_ms=120, pre_ms=120, min_ms=1000):
    combined = AudioSegment.silent(duration=0)
    durs = []
    for idx, p in enumerate(audio_paths):
        seg = AudioSegment.from_file(p)
        seg = AudioSegment.silent(duration=pre_ms) + seg
        if len(seg) < min_ms:
            seg += AudioSegment.silent(duration=min_ms - len(seg))
        seg_ms = len(seg)
        extra = gap_ms if idx < len(audio_paths) - 1 else 0
        combined += seg
        if extra:
            combined += AudioSegment.silent(duration=extra)
        durs.append((seg_ms + extra) / 1000.0)
    (TEMP / "full_raw.wav").unlink(missing_ok=True)
    combined.export(TEMP / "full_raw.wav", format="wav")
    return durs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ã‚³ãƒ³ãƒœå‡¦ç†
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_one(topic, turns, audio_lang, subs, title_lang, yt_privacy, account, do_upload, chunk_size):
    reset_temp()

    raw = (topic or "").replace("\r", "\n").strip()
    is_word_list = bool(re.search(r"[,;\n]", raw)) and len([w for w in re.split(r"[\n,;]+", raw) if w.strip()]) >= 2

    words_count = int(os.getenv("VOCAB_WORDS", "6"))
    if is_word_list:
        vocab_words = [w.strip() for w in re.split(r"[\n,;]+", raw) if w.strip()]
        theme = "custom list"
    else:
        theme = topic
        vocab_words = _gen_vocab_list(theme, audio_lang, words_count)

    # 3è¡Œãƒ–ãƒ­ãƒƒã‚¯: å˜èª â†’ å˜èª â†’ ä¾‹æ–‡
    dialogue = []
    for w in vocab_words:
        ex_raw = _gen_example_sentence(w, audio_lang)
        # â˜… ä¾‹æ–‡ã¯ã“ã“ã§æ—¢ã«ãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ã‚¹æ¸ˆï¼ˆ_gen_example_sentence å†…ï¼‰
        dialogue.extend([("N", w), ("N", w), ("N", ex_raw)])

    valid_dialogue = [(spk, line) for (spk, line) in dialogue if line.strip()]
    audio_parts, sub_rows = [], [[] for _ in subs]

    plain_lines = [line for (_, line) in valid_dialogue]
    tts_lines   = []

    for i, (spk, line) in enumerate(valid_dialogue, 1):
        role_idx = (i - 1) % 3  # 0/1/2

        # TTSãƒ†ã‚­ã‚¹ãƒˆ
        tts_line = line
        if audio_lang == "ja":
            if role_idx == 2:
                # ä¾‹æ–‡ã®æ‹¬å¼§ã¯TTSã§ã¯èª­ã¾ãªã„ï¼ˆå­—å¹•ã¯ãã®ã¾ã¾ï¼‰
                tts_line = _PARENS_JA.sub(" ", tts_line).strip()
            if role_idx in (0, 1) and _KANJI_ONLY.fullmatch(line):
                yomi = _kana_reading(line)
                if yomi:
                    tts_line = yomi
        # ä¾‹æ–‡æœ«å°¾ã®å¥èª­ç‚¹ã¯ç¢ºå®Ÿã«
        if role_idx == 2:
            tts_line = _ensure_period_for_sentence(tts_line, audio_lang)

        out_audio = TEMP / f"{i:02d}.wav"
        speak(audio_lang, spk, tts_line, out_audio, style="neutral")
        audio_parts.append(out_audio)
        tts_lines.append(tts_line)

        # å­—å¹•ï¼ˆéŸ³å£°è¨€èª=å°æœ¬åŸæ–‡ã€ä»–è¨€èª=ç¿»è¨³ï¼‰
        for r, lang in enumerate(subs):
            sub_rows[r].append(line if lang == audio_lang else translate(line, lang))

    # å˜ç´”çµåˆ â†’ æ•´éŸ³ â†’ mp3
    new_durs = _concat_with_gaps(audio_parts, gap_ms=GAP_MS, pre_ms=PRE_SIL_MS, min_ms=MIN_UTTER_MS)
    enhance(TEMP/"full_raw.wav", TEMP/"full.wav")
    AudioSegment.from_file(TEMP/"full.wav").export(TEMP/"full.mp3", format="mp3")

    # èƒŒæ™¯ç”»åƒ
    bg_png = TEMP / "bg.png"
    first_word = valid_dialogue[0][1] if valid_dialogue else theme
    fetch_bg(first_word, bg_png)

    # lines.json
    lines_data = []
    for i, ((spk, txt), dur) in enumerate(zip(valid_dialogue, new_durs)):
        row = [spk]
        for r in range(len(subs)):
            row.append(sub_rows[r][i])
        row.append(dur)
        lines_data.append(row)
    (TEMP/"lines.json").write_text(json.dumps(lines_data, ensure_ascii=False, indent=2), encoding="utf-8")

    if DEBUG_SCRIPT:
        try:
            (TEMP / "script_raw.txt").write_text("\n".join(plain_lines), encoding="utf-8")
            (TEMP / "script_tts.txt").write_text("\n".join(tts_lines), encoding="utf-8")
            with open(TEMP / "subs_table.tsv", "w", encoding="utf-8") as f:
                header = ["idx", "text"] + [f"sub:{code}" for code in subs]
                f.write("\t".join(header) + "\n")
                for idx in range(len(valid_dialogue)):
                    row = [str(idx+1), valid_dialogue[idx][1]] + [sub_rows[r][idx] for r in range(len(subs))]
                    f.write("\t".join(row) + "\n")
            with open(TEMP / "durations.txt", "w", encoding="utf-8") as f:
                total = 0.0
                for i, d in enumerate(new_durs, 1):
                    total += d
                    f.write(f"{i:02d}\t{d:.3f}s\n")
                f.write(f"TOTAL\t{total:.3f}s\n")
        except Exception as e:
            logging.warning(f"[DEBUG_SCRIPT] write failed: {e}")

    if args.lines_only:
        return

    # ã‚µãƒ ãƒ
    thumb = TEMP / "thumbnail.jpg"
    thumb_lang = subs[1] if len(subs) > 1 else audio_lang
    make_thumbnail(theme, thumb_lang, thumb)

    # å‹•ç”»ç”Ÿæˆ
    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    final_mp4 = OUTPUT / f"{audio_lang}-{'_'.join(subs)}_{stamp}.mp4"
    final_mp4.parent.mkdir(parents=True, exist_ok=True)

    cmd = [
        "python", str(BASE/"chunk_builder.py"),
        str(TEMP/"lines.json"), str(TEMP/"full.mp3"), str(bg_png),
        "--chunk", str(chunk_size),
        "--rows", str(len(subs)),
        "--out", str(final_mp4),
    ]
    logging.info("ğŸ”¹ chunk_builder cmd: %s", " ".join(cmd))
    subprocess.run(cmd, check=True)

    if not do_upload:
        return

    # ãƒ¡ã‚¿ç”Ÿæˆï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    title = make_title(theme, title_lang, audio_lang_for_label=audio_lang)
    desc  = make_desc(theme, title_lang)
    tags  = make_tags(theme, audio_lang, subs, title_lang)

    upload(video_path=final_mp4, title=title, desc=desc, tags=tags,
           privacy=yt_privacy, account=account, thumbnail=thumb, default_lang=audio_lang)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_all(topic, turns, privacy, do_upload, chunk_size):
    for combo in COMBOS:
        audio_lang  = combo["audio"]
        subs        = combo["subs"]
        account     = combo.get("account","default")
        title_lang  = _infer_title_lang(audio_lang, subs, combo)

        logging.info(f"=== Combo: {audio_lang}, subs={subs}, account={account}, title_lang={title_lang}, mode={CONTENT_MODE} ===")

        picked_topic = topic
        if topic.strip().lower() == "auto":
            picked_topic = pick_by_content_type("vocab", audio_lang)
            logging.info(f"[{audio_lang}] picked vocab theme: {picked_topic}")

        run_one(picked_topic, turns, audio_lang, subs, title_lang, privacy, account, do_upload, chunk_size)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
    ap = argparse.ArgumentParser()
    ap.add_argument("topic", help="èªå½™ãƒ†ãƒ¼ãƒã€‚AUTO ã§è‡ªå‹•é¸æŠã€‚ã‚«ãƒ³ãƒ/æ”¹è¡ŒåŒºåˆ‡ã‚Šãªã‚‰å˜èªãƒªã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨")
    ap.add_argument("--turns", type=int, default=8)  # äº’æ›ç”¨
    ap.add_argument("--privacy", default="unlisted", choices=["public","unlisted","private"])
    ap.add_argument("--lines-only", action="store_true")
    ap.add_argument("--no-upload", action="store_true")
    ap.add_argument("--chunk", type=int, default=9999, help="Shortsã¯åˆ†å‰²ã›ãš1æœ¬æ¨å¥¨")
    args = ap.parse_args()

    topic = resolve_topic(args.topic)
    run_all(topic, args.turns, args.privacy, not args.no_upload, args.chunk)