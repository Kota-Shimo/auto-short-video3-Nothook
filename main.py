#!/usr/bin/env python
"""
main.py â€“ VOCABå°‚ç”¨ç‰ˆï¼ˆå˜ç´”çµåˆï¼‹æ—¥æœ¬èªãµã‚ŠãŒãª[TTSã®ã¿]ï¼‹å…ˆé ­ç„¡éŸ³ï¼‹æœ€çŸ­1ç§’ï¼‰
- ä¾‹æ–‡ã¯å¸¸ã«ã€Œ1æ–‡ã ã‘ã€ã€‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—æ™‚ã¯æœ€å¤§3å›ã¾ã§å†ç”Ÿæˆã—ã€æœ€å¾Œã¯ãƒ•ã‚§ãƒ¼ãƒ«ã‚»ãƒ¼ãƒ•ã€‚
- ç¿»è¨³ï¼ˆå­—å¹•ï¼‰ã¯1è¡ŒåŒ–ã—ã€è¤‡æ–‡ã¯å…ˆé ­1æ–‡ã®ã¿æ¡ç”¨ã€‚URL/çµµæ–‡å­—/ä½™åˆ†ãªç©ºç™½ã‚’é™¤å»ã€‚
- è¿½åŠ : TARGET_ACCOUNT/--account ã§ combos ã‚’ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå˜ä½ã«çµã‚Šè¾¼ã¿å¯èƒ½ã€‚
- è¿½åŠ : topic_picker ã®æ–‡è„ˆãƒ’ãƒ³ãƒˆï¼ˆcontextï¼‰ã‚’ä¾‹æ–‡ç”Ÿæˆã«æ¸¡ã—ã¦æ—¥æœ¬èªå´©ã‚Œã‚’æŠ‘åˆ¶ã€‚
- è¿½åŠ : ãƒ©ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ«ï¼ˆå³å¯†ãƒ¢ãƒãƒªãƒ³ã‚¬ãƒ«ãƒ»è¨˜å·/æ³¨é‡ˆç¦æ­¢ï¼‰ã‚’ä¾‹æ–‡ç”Ÿæˆã«çµ±åˆã€‚
- è¿½åŠ : å˜èª2è¡Œã®å­—å¹•ã¯ã€Œä¾‹æ–‡ï¼‹ãƒ†ãƒ¼ãƒï¼‹å“è©ãƒ’ãƒ³ãƒˆã€ã§1èªã«ç¢ºå®šã™ã‚‹æ–‡è„ˆè¨³ã¸åˆ‡æ›¿ã€‚
"""

import argparse, logging, re, json, subprocess, os, sys  # â† sys ã‚’è¿½åŠ 
from datetime import datetime
from pathlib import Path
from shutil import rmtree

import yaml
from pydub import AudioSegment
from openai import OpenAI

from config         import BASE, OUTPUT, TEMP
from translate      import translate
from tts_openai     import speak
from audio_fx       import enhance
from bg_image       import fetch as fetch_bg
from thumbnail      import make_thumbnail
from upload_youtube import upload
from topic_picker   import pick_by_content_type

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GPT = OpenAI()
CONTENT_MODE = "vocab"
DEBUG_SCRIPT = os.getenv("DEBUG_SCRIPT", "0") == "1"
GAP_MS       = int(os.getenv("GAP_MS", "120"))
PRE_SIL_MS   = int(os.getenv("PRE_SIL_MS", "120"))
MIN_UTTER_MS = int(os.getenv("MIN_UTTER_MS", "1000"))

# â˜… æ—¥æœ¬èªã ã‘å€‹åˆ¥ã«èª¿æ•´ã§ãã‚‹ENVï¼ˆæœªè¨­å®šãªã‚‰é€šå¸¸å€¤ã‚’ç¶™æ‰¿ï¼‰
GAP_MS_JA       = int(os.getenv("GAP_MS_JA", str(GAP_MS)))
PRE_SIL_MS_JA   = int(os.getenv("PRE_SIL_MS_JA", str(PRE_SIL_MS)))
MIN_UTTER_MS_JA = int(os.getenv("MIN_UTTER_MS_JA", "800"))  # ãƒ‡ãƒ•ã‚©è»½ã‚çŸ­ç¸®

# ç”Ÿæˆæ™‚ã®æ¸©åº¦ï¼ˆå¿…è¦ãªã‚‰ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãï¼‰
EX_TEMP_DEFAULT = float(os.getenv("EX_TEMP", "0.35"))   # ä¾‹æ–‡
LIST_TEMP       = float(os.getenv("LIST_TEMP", "0.30")) # èªå½™ãƒªã‚¹ãƒˆ

LANG_NAME = {
    "en": "English", "pt": "Portuguese", "id": "Indonesian",
    "ja": "Japanese","ko": "Korean", "es": "Spanish",
}

JP_CONV_LABEL = {
    "en": "è‹±ä¼šè©±", "ja": "æ—¥æœ¬èªä¼šè©±", "es": "ã‚¹ãƒšã‚¤ãƒ³èªä¼šè©±",
    "pt": "ãƒãƒ«ãƒˆã‚¬ãƒ«èªä¼šè©±", "ko": "éŸ“å›½èªä¼šè©±", "id": "ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èªä¼šè©±",
}

with open(BASE / "combos.yaml", encoding="utf-8") as f:
    COMBOS = yaml.safe_load(f)["combos"]

def reset_temp():
    if TEMP.exists():
        rmtree(TEMP)
    TEMP.mkdir(exist_ok=True)

def sanitize_title(raw: str) -> str:
    title = re.sub(r"^\s*(?:\d+\s*[.)]|[-â€¢ãƒ»])\s*", "", raw)
    title = re.sub(r"[\s\u3000]+", " ", title).strip()
    return title[:97] + "â€¦" if len(title) > 100 else title or "Auto Video"

def _infer_title_lang(audio_lang: str, subs: list[str], combo: dict) -> str:
    if "title_lang" in combo and combo["title_lang"]:
        return combo["title_lang"]
    if len(subs) >= 2:
        return subs[1]
    for s in subs:
        if s != audio_lang:
            return s
    return audio_lang

def resolve_topic(arg_topic: str) -> str:
    # æ‰‹å…¥åŠ›ã® topic ã¯ãã®ã¾ã¾é€šã™ï¼ˆAUTOæ™‚ã®å‡¦ç†ã¯ run_all å†…ã§å®Ÿæ–½ï¼‰
    return arg_topic

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³å…±é€š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_URL_RE   = re.compile(r"https?://\S+")
_NUM_LEAD = re.compile(r"^\s*\d+[\).:\-]\s*")
_QUOTES   = re.compile(r'^[\"â€œâ€\']+|[\"â€œâ€\']+$')
_EMOJI_RE = re.compile(r"[\U00010000-\U0010ffff]")  # ã–ã£ãã‚Šçµµæ–‡å­—
_SENT_END = re.compile(r"[ã€‚.!?ï¼ï¼Ÿ]")

def _normalize_spaces(t: str) -> str:
    return re.sub(r"\s+", " ", (t or "")).strip()

def _clean_strict(text: str) -> str:
    t = (text or "").strip()
    t = _URL_RE.sub("", t)
    t = _NUM_LEAD.sub("", t)
    t = _QUOTES.sub("", t)
    t = _EMOJI_RE.sub("", t)
    # æœ«å°¾ã®ä½™è¨ˆãªè¨˜å·
    t = re.sub(r"[\:\-â€“â€”]\s*$", "", t)
    return _normalize_spaces(t)

def _is_single_sentence(text: str) -> bool:
    return len(_SENT_END.findall(text or "")) <= 1

def _fits_length(text: str, lang_code: str) -> bool:
    if lang_code in ("ja", "ko", "zh"):
        return len(text or "") <= 30
    # è‹±èªãªã©ã¯èªæ•°ã§
    return len(re.findall(r"\b\w+\b", text or "")) <= 12

def _ensure_period_for_sentence(txt: str, lang_code: str) -> str:
    t = txt or ""
    return t if re.search(r"[ã€‚.!?ï¼ï¼Ÿ]$", t) else t + ("ã€‚" if lang_code == "ja" else ".")

# å­—å¹•ç”¨ã‚¯ãƒªãƒ¼ãƒ³ï¼ˆç¿»è¨³çµæœã«é©ç”¨ï¼‰
def _clean_sub_line(text: str, lang_code: str) -> str:
    t = _clean_strict(text).replace("\n", " ").strip()
    # è¤‡æ–‡ã¯ã€Œæœ€åˆã®çµ‚æ­¢ã¾ã§ã€ã‚’æ¡ç”¨
    m = _SENT_END.search(t)
    if m:
        end = m.end()
        t = t[:end]
    return t

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç¿»è¨³ã®å¼·åŒ–ï¼ˆä¾‹æ–‡ç”¨ï¼‰ï¼štranslate()ãŒåŸæ–‡ã®ã¾ã¾è¿”ã™å ´åˆã®å†å®Ÿè¡Œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_ASCII_ONLY = re.compile(r'^[\x00-\x7F]+$')

def _looks_like_english(s: str) -> bool:
    s = (s or "").strip()
    return bool(_ASCII_ONLY.fullmatch(s)) and bool(re.search(r'[A-Za-z]', s))

def _needs_retranslate(output: str, src_lang: str, target_lang: str, original: str) -> bool:
    if target_lang == src_lang:
        return False
    out = (output or "").strip()
    if not out:
        return True
    if out.lower() == (original or "").strip().lower():
        return True
    if target_lang == "en" and not _looks_like_english(out):
        return True
    return False

def translate_sentence_strict(sentence: str, src_lang: str, target_lang: str) -> str:
    """ã¾ãšæ—¢å­˜ translate ã‚’ä½¿ã„ã€å¿…è¦ãªã‚‰å³å¯†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†ç¿»è¨³ã™ã‚‹ã€‚"""
    try:
        first = translate(sentence, target_lang)
    except Exception:
        first = ""

    if not _needs_retranslate(first, src_lang, target_lang, sentence):
        return _clean_sub_line(first, target_lang)

    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role":"user",
                "content":(
                    f"Translate from {LANG_NAME.get(src_lang,'source language')} "
                    f"to {LANG_NAME.get(target_lang,'target language')}.\n"
                    "Return ONLY the translation as a single sentence. "
                    "No explanations, no quotes, no extra symbols.\n\n"
                    f"Text: {sentence}"
                )
            }],
            temperature=0.0, top_p=1.0
        )
        out = (rsp.choices[0].message.content or "").strip()
        out = _clean_sub_line(out, target_lang)
        if out:
            return out
    except Exception:
        pass

    # ãƒ•ã‚§ã‚¤ãƒ«ã‚»ãƒ¼ãƒ•ï¼šæœ€æ‚ªã¯åŸæ–‡ã‚’è¿”ã™ï¼ˆãã®å¾Œ _clean_sub_line ãŒåŠ¹ãï¼‰
    return _clean_sub_line(sentence, target_lang)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ©ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ«ï¼ˆå³å¯†ãƒ¢ãƒãƒªãƒ³ã‚¬ãƒ« & è¨˜å·/æ³¨é‡ˆç¦æ­¢ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _lang_rules(lang_code: str) -> str:
    if lang_code == "ja":
        return (
            "Write entirely in Japanese. "
            "Do not include Latin letters or other languages. "
            "Avoid ASCII symbols such as '/', '-', 'â†’', '()', '[]', '<>', and '|'. "
            "No translation glosses, brackets, or country/language mentions."
        )
    lang_name = LANG_NAME.get(lang_code, "English")
    return (
            f"Write entirely in {lang_name}. "
            "Do not code-switch or include other writing systems. "
            "Avoid ASCII symbols like '/', '-', 'â†’', '()', '[]', '<>', and '|'. "
            "No translation glosses, brackets, or country/language mentions."
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ—¥æœ¬èªå‘ã‘ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼ˆfallback ç”¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _guess_ja_pos(word: str) -> str:
    """
    ã–ã£ãã‚Šå“è©æ¨å®šï¼ˆè¾æ›¸ãªã—è»½é‡ï¼‰
    æˆ»ã‚Šå€¤: "verb" / "iadj" / "naadj" / "noun"
    """
    w = (word or "").strip()
    if not w:
        return "noun"
    if w.endswith(("ã™ã‚‹", "ã—ã¾ã™", "ã—ãŸã„", "ã—ãŸ", "ã—ãªã„", "ã—ã‚ˆã†")):
        return "verb"
    if re.search(r"(ã†|ã|ã|ã™|ã¤|ã¬|ã‚€|ã¶|ã‚‹)$", w):
        return "verb"
    if w.endswith("ã„"):
        return "iadj"
    if w.endswith(("çš„", "çš„ãª", "é¢¨")):
        return "naadj"
    if re.fullmatch(r"[ã‚¡-ãƒ¶ãƒ¼]+", w):
        return "noun"
    return "noun"

def _ja_template_fallback(word: str) -> str:
    kind = _guess_ja_pos(word)
    if kind == "verb":
        return f"{word}ã¨ã“ã‚ã§ã™ã€‚"
    if kind == "iadj":
        return f"{word}ã§ã™ã­ã€‚"
    if kind == "naadj":
        return f"{word}ã ã­ã€‚"
    return f"{word}ãŒå¿…è¦ã§ã™ã€‚"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# èªå½™ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _example_temp_for(lang_code: str) -> float:
    # æ—¥æœ¬èªã¯ç‰¹ã«å´©ã‚Œã‚„ã™ã„ã®ã§ã•ã‚‰ã«ä½æ¸©åº¦
    return 0.20 if lang_code == "ja" else EX_TEMP_DEFAULT

def _gen_example_sentence(word: str, lang_code: str, context_hint: str = "") -> str:
    """
    1æ–‡ã ã‘ç”Ÿæˆã€‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ä¸åˆæ ¼ãªã‚‰æœ€å¤§3å›ã¾ã§å†ç”Ÿæˆã€‚
    å¤±æ•—æ™‚ãƒ•ã‚§ãƒ¼ãƒ«ã‚»ãƒ¼ãƒ•ï¼ˆja: ãƒ†ãƒ³ãƒ—ãƒ¬ / ä»–è¨€èª: Let's practice ...ï¼‰
    context_hint ã‚’æ–‡è„ˆãƒ’ãƒ³ãƒˆã¨ã—ã¦æ´»ç”¨ã€‚
    """
    lang_name = LANG_NAME.get(lang_code, "English")
    ctx = (context_hint or "").strip()

    rules = _lang_rules(lang_code)

    system = {
        "role": "system",
        "content": (
            "You write exactly ONE natural sentence. "
            "No lists, no quotes, no emojis, no URLs. Keep it monolingual."
        ),
    }

    if lang_code == "ja":
        user = (
            f"{rules} "
            f"å˜èªã€Œ{word}ã€ã‚’å¿…ãšå«ã‚ã¦ã€æ—¥æœ¬èªã§è‡ªç„¶ãªä¸€æ–‡ã‚’ã¡ã‚‡ã†ã©1ã¤ã ã‘æ›¸ã„ã¦ãã ã•ã„ã€‚"
            "æ—¥å¸¸ã®ç°¡å˜ãªçŠ¶æ³ã‚’æƒ³å®šã—ã€åŠ©è©ã®ä½¿ã„æ–¹ã‚’è‡ªç„¶ã«ã—ã¦ãã ã•ã„ã€‚"
            "ã‹ã£ã“æ›¸ãã‚„ç¿»è¨³æ³¨é‡ˆã¯ä¸è¦ã§ã™ã€‚"
        )
        if ctx:
            user += f" ã‚·ãƒ¼ãƒ³ã®æ–‡è„ˆ: {ctx}"
    else:
        user = (
            f"{rules} "
            f"Write exactly ONE short, natural sentence in {lang_name} that uses the word: {word}. "
            "Return ONLY the sentence."
        )
        if ctx:
            user += f" Scene hint: {ctx}"

    for _ in range(3):
        try:
            rsp = GPT.chat.completions.create(
                model="gpt-4o-mini",
                messages=[system, {"role":"user","content":user}],
                temperature=_example_temp_for(lang_code),
                top_p=0.9,
                presence_penalty=0,
                frequency_penalty=0,
            )
            raw = (rsp.choices[0].message.content or "").strip()
        except Exception:
            raw = ""

        cand = _clean_strict(raw)
        valid = bool(cand) and _is_single_sentence(cand) and _fits_length(cand, lang_code)
        try:
            contains_word = (word.lower() in cand.lower()) if lang_code not in ("ja","ko","zh") else (word in cand)
        except Exception:
            contains_word = True

        if valid and contains_word:
            return _ensure_period_for_sentence(cand, lang_code)

    # ãƒ•ã‚§ãƒ¼ãƒ«ã‚»ãƒ¼ãƒ•
    if lang_code == "ja":
        return _ja_template_fallback(word)
    return _ensure_period_for_sentence(f"Let's practice {word}", lang_code)

def _gen_vocab_list(theme: str, lang_code: str, n: int) -> list[str]:
    theme_for_prompt = translate(theme, lang_code) if lang_code != "en" else theme
    prompt = (
        f"List {n} essential single or hyphenated words for {theme_for_prompt} context "
        f"in {LANG_NAME.get(lang_code,'English')}. Return ONLY one word per line, no numbering."
    )
    content = ""
    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"user","content":prompt}],
            temperature=LIST_TEMP,
            top_p=0.9,
            presence_penalty=0,
            frequency_penalty=0,
        )
        content = (rsp.choices[0].message.content or "")
    except Exception:
        content = ""

    words = []
    for line in content.splitlines():
        w = (line or "").strip()
        if not w:
            continue
        w = re.sub(r"^\d+[\).]?\s*", "", w)     # ç•ªå·
        w = re.sub(r"[ï¼Œã€ã€‚.!?ï¼ï¼Ÿ]+$", "", w)  # æœ«å°¾å¥èª­ç‚¹
        w = w.split()[0]                        # å…ˆé ­ãƒˆãƒ¼ã‚¯ãƒ³
        if w and w not in words:
            words.append(w)

    if len(words) >= n:
        return words[:n]
    fallback = ["check-in", "reservation", "checkout", "receipt", "elevator", "lobby", "upgrade"]
    return fallback[:n]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â˜… è¿½åŠ ï¼šspec æ­£è¦åŒ–ï¼‹specå¯¾å¿œã®èªå½™ç”Ÿæˆï¼ˆä¸‹ä½äº’æ›ä¿æŒï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _normalize_spec(picked, context_hint, audio_lang, words_env_count: int):
    """
    topic_picker ã‹ã‚‰ã®æˆ»ã‚Šå€¤ã‚’æ­£è¦åŒ–:
      - dict(spec) ã‚’ãã®ã¾ã¾å—ã‘å…¥ã‚Œã€æ¬ æã¯è£œå®Œ
      - (theme, ctx) ãªã‚‰ spec ã‚’è–„ãåˆæˆ
      - str(theme) ãªã‚‰æ—¢å­˜äº’æ›ã®æœ€å° spec ã‚’ç”Ÿæˆ
    è¿”ã‚Šå€¤: (theme, context, spec)
    """
    if isinstance(picked, dict):
        theme = picked.get("theme") or "general vocabulary"
        ctx   = picked.get("context") or (context_hint or "")
        spec  = dict(picked)  # ã‚³ãƒ”ãƒ¼
        if "count" not in spec or not isinstance(spec["count"], int):
            spec["count"] = words_env_count
        return theme, ctx, spec

    if isinstance(picked, tuple) and len(picked) == 2:
        theme, ctx = picked[0], picked[1]
        spec = {
            "theme": theme,
            "context": ctx or (context_hint or ""),
            "count": words_env_count,
        }
        return theme, ctx, spec

    # string / ãã®ä»–
    theme = str(picked)
    ctx   = context_hint or ""
    spec = {
        "theme": theme,
        "context": ctx,
        "count": words_env_count,
    }
    return theme, ctx, spec

def _gen_vocab_list_from_spec(spec: dict, lang_code: str) -> list[str]:
    """
    spec ã«å«ã¾ã‚Œã‚‹åŸºæº–ï¼ˆpos / relation_mode / difficulty / pattern_hint / morphology / count ãªã©ï¼‰ã‚’
    ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åæ˜ ã€‚æœªæŒ‡å®šã¯å¾“æ¥æŒ™å‹•ã€‚
    """
    n   = int(spec.get("count", int(os.getenv("VOCAB_WORDS", "6"))))
    th  = spec.get("theme") or "general vocabulary"
    pos = spec.get("pos") or []  # ["noun","verb",...]
    rel = (spec.get("relation_mode") or "").strip().lower()  # synonym/antonym/collocation/pattern
    diff = (spec.get("difficulty") or "").strip().upper()    # A1/A2/B1...
    patt = (spec.get("pattern_hint") or "").strip()
    morph = spec.get("morphology") or []                     # ["prefix:un-","suffix:-able"]

    theme_for_prompt = translate(th, lang_code) if lang_code != "en" else th

    lines = []
    lines.append(f"You are selecting {n} HIGH-FREQUENCY words for the topic: {theme_for_prompt}.")
    if pos:
        lines.append("Restrict part-of-speech to: " + ", ".join(pos) + ".")
    if rel == "synonym":
        lines.append("Prefer synonyms or near-synonyms around the central topic.")
    elif rel == "antonym":
        lines.append("Include at least one meaningful antonym pair if possible.")
    elif rel == "collocation":
        lines.append("Prefer common collocations used with the topic in everyday speech.")
    elif rel == "pattern":
        lines.append("Prefer short reusable patterns or set phrases.")
    if patt:
        lines.append(f"Pattern focus hint: {patt}.")
    if morph:
        lines.append("If natural, include related morphological family: " + ", ".join(morph) + ".")
    if diff in ("A1","A2","B1"):
        lines.append(f"Target approximate CEFR level: {diff}. Keep words short and common for this level.")
    lines.append("Return ONLY one word or short hyphenated term per line, no numbering, no punctuation.")
    prompt = "\n".join(lines)

    content = ""
    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"user","content":prompt}],
            temperature=LIST_TEMP,
            top_p=0.9,
            presence_penalty=0,
            frequency_penalty=0,
        )
        content = (rsp.choices[0].message.content or "")
    except Exception:
        content = ""

    words = []
    for line in content.splitlines():
        w = (line or "").strip()
        if not w:
            continue
        w = re.sub(r"^\d+[\).]?\s*", "", w)     # ç•ªå·é™¤å»
        w = re.sub(r"[ï¼Œã€ã€‚.!?ï¼ï¼Ÿ]+$", "", w)  # æœ«å°¾å¥èª­ç‚¹é™¤å»
        w = w.split()[0]                        # å…ˆé ­ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
        if w and w not in words:
            words.append(w)

    if len(words) >= n:
        return words[:n]

    # ä¸è¶³æ™‚ã¯å¾“æ¥ fallback
    fallback = ["check-in", "reservation", "checkout", "receipt", "elevator", "lobby", "upgrade"]
    return (words + [w for w in fallback if w not in words])[:n]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ—¥æœ¬èªTTSç”¨ãµã‚ŠãŒãª
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_KANJI_ONLY = re.compile(r"^[ä¸€-é¾¥ã€…]+$")
_PARENS_JA  = re.compile(r"\s*[\(\ï¼ˆ][^)\ï¼‰]{1,40}[\)\ï¼‰]\s*")

def _kana_reading(word: str) -> str:
    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role":"user",
                "content":(
                    "æ¬¡ã®æ—¥æœ¬èªå˜èªã®èª­ã¿ã‚’ã²ã‚‰ãŒãªã ã‘ã§1èªè¿”ã—ã¦ãã ã•ã„ã€‚"
                    "è¨˜å·ãƒ»æ‹¬å¼§ãƒ»èª¬æ˜ã¯ä¸è¦ã€‚\n"
                    f"å˜èª: {word}"
                )
            }],
            temperature=0.0,
            top_p=1.0,
        )
        yomi = (rsp.choices[0].message.content or "").strip()
        yomi = re.sub(r"[^ã-ã‚–ã‚ã‚ãƒ¼]+", "", yomi)
        return yomi[:20]
    except Exception:
        return ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä¾‹æ–‡å–å¾—ï¼ˆåŒã˜3è¡Œãƒ–ãƒ­ãƒƒã‚¯ã®3è¡Œç›®ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _example_for_index(valid_dialogue: list[tuple[str, str]], idx0: int) -> str:
    """
    valid_dialogue ã¯ 3è¡Œ1çµ„ï¼ˆ[word, word, example]ï¼‰ã§ä¸¦ã¶ã€‚
    idx0 ãŒãã®çµ„ã® 0/1/2 ã®ã„ãšã‚Œã§ã‚‚ã€ä¾‹æ–‡ã¯å¸¸ã« +2 ã®ä½ç½®ã€‚
    """
    role_idx = idx0 % 3  # 0/1/2
    base = idx0 - role_idx
    ex_pos = base + 2
    if 0 <= ex_pos < len(valid_dialogue):
        return valid_dialogue[ex_pos][1]
    return ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å˜èªå°‚ç”¨ãƒ»æ–‡è„ˆã¤ãç¿»è¨³ï¼ˆ1èªã ã‘è¿”ã™ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def translate_word_context(word: str, target_lang: str, src_lang: str, theme: str, example: str, pos_hint: str | None = None) -> str:
    """
    å˜èªã®æ„å‘³ã‚’ ä¾‹æ–‡ï¼‹ãƒ†ãƒ¼ãƒï¼‹å“è©ãƒ’ãƒ³ãƒˆ ã§ç¢ºå®šã—ã€target_lang ã®â€œ1èªã®ã¿â€ã‚’è¿”ã™ã€‚
    """
    theme = (theme or "").strip()
    example = (example or "").strip()
    pos_line = f"Part of speech hint: {pos_hint}." if pos_hint else ""

    prompt_lines = [
        "You are a precise bilingual lexicon generator.",
        f"Source language code: {src_lang}",
        f"Target language code: {target_lang}",
        "Task: Translate the SINGLE WORD below into exactly ONE natural target-language word that matches the intended meaning in the given context.",
        "Rules:",
        "- Output ONLY one word, no punctuation, no quotes, no explanations.",
        "- Choose the sense that fits the context (theme and example sentence).",
        "- Avoid month-name or book-title senses unless clearly indicated by context.",
        pos_line,
        "",
        f"Word: {word}",
        f"Theme: {theme}" if theme else "Theme: (none)",
        f"Example sentence for context: {example}" if example else "Example sentence for context: (none)",
    ]
    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"user","content":"\n".join(prompt_lines)}],
            temperature=0.0, top_p=1.0
        )
        out = (rsp.choices[0].message.content or "").strip()
        out = re.sub(r"[ï¼Œã€ã€‚.!?ï¼ï¼Ÿ]+$", "", out).strip()
        out = out.split()[0] if out else ""
        return out or word
    except Exception:
        return word

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¿ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«è¨€èªã«çµ±ä¸€ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_title(theme, title_lang: str, audio_lang_for_label: str | None = None):
    if title_lang not in LANG_NAME:
        title_lang = "en"
    try:
        theme_local = theme if title_lang == "en" else translate(theme, title_lang)
    except Exception:
        theme_local = theme

    if title_lang == "ja":
        base = f"{theme_local} ã§ä½¿ãˆã‚‹ä¸€è¨€"
        label = JP_CONV_LABEL.get(audio_lang_for_label or "", "")
        t = f"{label} {base}" if label and label not in base else base
        return sanitize_title(t)[:28]
    else:
        if title_lang == "en":
            t = f"{theme_local.capitalize()} vocab in one minute"
        else:
            t = f"{theme_local} vocabulary"
        return sanitize_title(t)[:55]

def make_desc(theme, title_lang: str):
    if title_lang not in LANG_NAME:
        title_lang = "en"
    try:
        theme_local = theme if title_lang == "en" else translate(theme, title_lang)
    except Exception:
        theme_local = theme

    msg = {
        "ja": f"{theme_local} ã«å¿…é ˆã®èªå½™ã‚’çŸ­æ™‚é–“ã§ãƒã‚§ãƒƒã‚¯ã€‚å£°ã«å‡ºã—ã¦ä¸€ç·’ã«ç·´ç¿’ã—ã‚ˆã†ï¼ #vocab #learning",
        "en": f"Quick practice for {theme_local} vocabulary. Repeat after the audio! #vocab #learning",
        "pt": f"Pratique rÃ¡pido o vocabulÃ¡rio de {theme_local}. Repita em voz alta! #vocab #aprendizado",
        "es": f"PrÃ¡ctica rÃ¡pida de vocabulario de {theme_local}. Â¡Repite en voz alta! #vocab #aprendizaje",
        "ko": f"{theme_local} ì–´íœ˜ë¥¼ ë¹ ë¥´ê²Œ ì—°ìŠµí•˜ì„¸ìš”. ì†Œë¦¬ ë‚´ì–´ ë”°ë¼ ë§í•´ìš”! #vocab #learning",
        "id": f"Latihan cepat kosakata {theme_local}. Ucapkan keras-keras! #vocab #belajar",
    }
    return msg.get(title_lang, msg["en"])

def make_tags(theme, audio_lang, subs, title_lang):
    tags = [
        theme, "vocabulary", "language learning", "speaking practice",
        "listening practice", "subtitles"
    ]
    for code in subs:
        if code in LANG_NAME:
            tags.append(f"{LANG_NAME[code]} subtitles")
    seen, out = set(), []
    for t in tags:
        if t not in seen:
            seen.add(t); out.append(t)
    return out[:15]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å˜ç´”çµåˆï¼ˆWAVä¸­é–“ãƒ»è¡Œé ­ç„¡éŸ³ãƒ»æœ€çŸ­å°ºãƒ»è¡Œé–“ã‚®ãƒ£ãƒƒãƒ—ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _concat_with_gaps(audio_paths, gap_ms=120, pre_ms=120, min_ms=1000):
    combined = AudioSegment.silent(duration=0)
    durs = []
    for idx, p in enumerate(audio_paths):
        seg = AudioSegment.from_file(p)
        seg = AudioSegment.silent(duration=pre_ms) + seg
        if len(seg) < min_ms:
            seg += AudioSegment.silent(duration=min_ms - len(seg))
        seg_ms = len(seg)
        extra = gap_ms if idx < len(audio_paths) - 1 else 0
        combined += seg
        if extra:
            combined += AudioSegment.silent(duration=extra)
        durs.append((seg_ms + extra) / 1000.0)
    (TEMP / "full_raw.wav").unlink(missing_ok=True)
    combined.export(TEMP / "full_raw.wav", format="wav")
    return durs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ã‚³ãƒ³ãƒœå‡¦ç†
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_one(topic, turns, audio_lang, subs, title_lang, yt_privacy, account, do_upload, chunk_size, context_hint="", spec=None):
    reset_temp()

    raw = (topic or "").replace("\r", "\n").strip()
    is_word_list = bool(re.search(r"[,;\n]", raw)) and len([w for w in re.split(r"[\n,;]+", raw) if w.strip()]) >= 2

    words_count = int(os.getenv("VOCAB_WORDS", "6"))
    if is_word_list:
        vocab_words = [w.strip() for w in re.split(r"[\n,;]+", raw) if w.strip()]
        theme = "custom list"
        local_context = ""  # æ‰‹å…¥åŠ›ãƒªã‚¹ãƒˆæ™‚ã¯æ–‡è„ˆãƒ’ãƒ³ãƒˆãªã—
    else:
        # spec ãŒæ¥ã¦ã„ã‚Œã°ãã‚Œã‚’ä½¿ç”¨
        if isinstance(spec, dict):
            theme = spec.get("theme") or topic
            local_context = (spec.get("context") or context_hint or "")
            vocab_words = _gen_vocab_list_from_spec(spec, audio_lang)
            # ãƒ‡ãƒãƒƒã‚°: spec ã‚’ä¿å­˜ï¼ˆå¸¸ã«OKï¼‰
            try:
                (TEMP / "spec.json").write_text(json.dumps(spec, ensure_ascii=False, indent=2), encoding="utf-8")
            except Exception:
                pass
        else:
            theme = topic
            vocab_words = _gen_vocab_list(theme, audio_lang, words_count)
            local_context = context_hint or ""  # AUTOæ™‚ã«å—ã‘å–ã£ãŸæ–‡è„ˆã‚’ä½¿ã†

    # 3è¡Œãƒ–ãƒ­ãƒƒã‚¯: å˜èª â†’ å˜èª â†’ ä¾‹æ–‡
    dialogue = []
    for w in vocab_words:
        ex = _gen_example_sentence(w, audio_lang, local_context)
        dialogue.extend([("N", w), ("N", w), ("N", ex)])

    valid_dialogue = [(spk, line) for (spk, line) in dialogue if line.strip()]
    audio_parts, sub_rows = [], [[] for _ in subs]

    plain_lines = [line for (_, line) in valid_dialogue]
    tts_lines   = []

    for i, (spk, line) in enumerate(valid_dialogue, 1):
        role_idx = (i - 1) % 3  # 0/1/2

        tts_line = line
        if audio_lang == "ja":
            if role_idx == 2:
                # ä¾‹æ–‡ï¼šæ‹¬å¼§ã¯èª­ã¾ãªã„ + å¿…ãšçµ‚æ­¢
                tts_line = _PARENS_JA.sub(" ", tts_line).strip()
                tts_line = _ensure_period_for_sentence(tts_line, audio_lang)
            else:
                # å˜èªè¡Œï¼šã‹ãªèª­ã¿ï¼‹å¥ç‚¹ã§æŠ‘æšå®‰å®šï¼ˆãŸã ã—1æ–‡å­—èªã¯å¥ç‚¹ã‚’ä»˜ã‘ãªã„ï¼‰
                if _KANJI_ONLY.fullmatch(line):
                    yomi = _kana_reading(line)
                    if yomi:
                        tts_line = yomi
                base = re.sub(r"[ã€‚ï¼ï¼Ÿ!?]+$", "", tts_line).strip()
                tts_line = base + "ã€‚" if len(base) >= 2 else base
        else:
            # éæ—¥æœ¬èªã¯ä¾‹æ–‡ã®ã¿çµ‚æ­¢ã‚’ä¿è¨¼
            if role_idx == 2:
                tts_line = _ensure_period_for_sentence(tts_line, audio_lang)

        out_audio = TEMP / f"{i:02d}.wav"
        # æ—¥æœ¬èªã¯èªå°¾å®‰å®šã®ãŸã‚ serious
        style_for_tts = "serious" if audio_lang == "ja" else "neutral"

        speak(audio_lang, spk, tts_line, out_audio, style=style_for_tts)
        audio_parts.append(out_audio)
        tts_lines.append(tts_line)

        # å­—å¹•ï¼ˆéŸ³å£°è¨€èª=åŸæ–‡ã€ä»–è¨€èª=ç¿»è¨³ï¼‰â†’ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦1è¡ŒåŒ–
        for r, lang in enumerate(subs):
            if lang == audio_lang:
                sub_rows[r].append(_clean_sub_line(line, lang))
            else:
                try:
                    if role_idx in (0, 1):  # å˜èª2è¡Œã¯æ–‡è„ˆã¤ã1èªè¨³
                        example_ctx = _example_for_index(valid_dialogue, i-1)
                        # POSãƒ’ãƒ³ãƒˆï¼šspecå„ªå…ˆâ†’æ—¥æœ¬èªã®ã¿ç°¡æ˜“æ¨å®š
                        pos_hint = None
                        if isinstance(spec, dict) and spec.get("pos"):
                            pos_hint = ",".join(spec["pos"])
                        elif audio_lang == "ja":
                            _k = _guess_ja_pos(line)
                            pos_map = {"verb":"verb", "iadj":"adjective", "naadj":"adjective", "noun":"noun"}
                            pos_hint = pos_map.get(_k, None)

                        trans = translate_word_context(
                            word=line, target_lang=lang, src_lang=audio_lang,
                            theme=theme, example=example_ctx, pos_hint=pos_hint
                        )
                    else:
                        # ä¾‹æ–‡è¡Œã¯ã¾ãšé€šå¸¸ç¿»è¨³ â†’ ãƒ€ãƒ¡ãªã‚‰å³å¯†ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†ç¿»è¨³
                        trans = translate_sentence_strict(line, src_lang=audio_lang, target_lang=lang)
                except Exception:
                    trans = line
                sub_rows[r].append(_clean_sub_line(trans, lang))

    # å˜ç´”çµåˆ â†’ æ•´éŸ³ â†’ mp3
    # â˜… æ—¥æœ¬èªã ã‘é–“ã¨æœ€çŸ­å°ºã‚’åˆ¥ENVã§èª¿æ•´
    gap_ms = GAP_MS_JA if audio_lang == "ja" else GAP_MS
    pre_ms = PRE_SIL_MS_JA if audio_lang == "ja" else PRE_SIL_MS
    min_ms = MIN_UTTER_MS_JA if audio_lang == "ja" else MIN_UTTER_MS

    new_durs = _concat_with_gaps(audio_parts, gap_ms=gap_ms, pre_ms=pre_ms, min_ms=min_ms)
    enhance(TEMP/"full_raw.wav", TEMP/"full.wav")
    AudioSegment.from_file(TEMP/"full.wav").export(TEMP/"full.mp3", format="mp3")

    # èƒŒæ™¯ç”»åƒï¼ˆæ—¥æœ¬èªãƒ†ãƒ¼ãƒã‚’è‹±èªã«ç¿»è¨³ã—ã¦æ¤œç´¢ï¼‰
    bg_png = TEMP / "bg.png"

    try:
        theme_en = translate(theme, "en")  # æ—¥æœ¬èªãƒ†ãƒ¼ãƒã‚’è‹±èªåŒ–
    except Exception:
        theme_en = theme

    first_word = valid_dialogue[0][1] if valid_dialogue else theme

    def _is_ascii(s: str) -> bool:
        try:
            s.encode("ascii")
            return True
        except Exception:
            return False

    # æ¤œç´¢ã‚¯ã‚¨ãƒª
    if not _is_ascii(first_word or ""):
        query_for_bg = theme_en or "language learning"
    else:
        query_for_bg = first_word or theme_en or "learning"

    fetch_bg(query_for_bg, bg_png)
    
    # lines.json
    lines_data = []
    for i, ((spk, txt), dur) in enumerate(zip(valid_dialogue, new_durs)):
        row = [spk]
        for r in range(len(subs)):
            row.append(sub_rows[r][i])
        row.append(dur)
        lines_data.append(row)
    (TEMP/"lines.json").write_text(json.dumps(lines_data, ensure_ascii=False, indent=2), encoding="utf-8")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›ï¼ˆå¸¸ã«å‡ºåŠ›ã™ã‚‹ï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        (TEMP / "script_raw.txt").write_text("\n".join(plain_lines), encoding="utf-8")
        (TEMP / "script_tts.txt").write_text("\n".join(tts_lines), encoding="utf-8")
        with open(TEMP / "subs_table.tsv", "w", encoding="utf-8") as f:
            header = ["idx", "text"] + [f"sub:{code}" for code in subs]
            f.write("\t".join(header) + "\n")
            for idx in range(len(valid_dialogue)):
                row = [str(idx+1), _clean_sub_line(valid_dialogue[idx][1], audio_lang)]
                for r in range(len(subs)):
                    row.append(sub_rows[r][idx])
                f.write("\t".join(row) + "\n")
        with open(TEMP / "durations.txt", "w", encoding="utf-8") as f:
            total = 0.0
            for i, d in enumerate(new_durs, 1):
                total += d
                f.write(f"{i:02d}\t{d:.3f}s\n")
            f.write(f"TOTAL\t{total:.3f}s\n")
    except Exception as e:
        logging.warning(f"[DEBUG_SCRIPT] write failed: {e}")

    if args.lines_only:
        return

    # ã‚µãƒ ãƒ
    thumb = TEMP / "thumbnail.jpg"
    thumb_lang = subs[1] if len(subs) > 1 else audio_lang
    make_thumbnail(theme, thumb_lang, thumb)

    # å‹•ç”»ç”Ÿæˆ
    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    final_mp4 = OUTPUT / f"{audio_lang}-{'_'.join(subs)}_{stamp}.mp4"
    final_mp4.parent.mkdir(parents=True, exist_ok=True)

    cmd = [
        "python", str(BASE/"chunk_builder.py"),
        str(TEMP/"lines.json"), str(TEMP/"full.mp3"), str(bg_png),
        "--chunk", str(chunk_size),
        "--rows", str(len(subs)),
        "--out", str(final_mp4),
    ]
    logging.info("ğŸ”¹ chunk_builder cmd: %s", " ".join(cmd))
    subprocess.run(cmd, check=True)

    if not do_upload:
        return

    # ãƒ¡ã‚¿ç”Ÿæˆï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    title = make_title(theme, title_lang, audio_lang_for_label=audio_lang)
    desc  = make_desc(theme, title_lang)
    tags  = make_tags(theme, audio_lang, subs, title_lang)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # æ”¹è‰¯ç‰ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ‡ã‚Œï¼†ä¸Šé™å¯¾å¿œï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _is_limit_error(err: Exception) -> bool:
        s = str(err)
        return (
            "uploadLimitExceeded" in s or
            "quotaExceeded" in s or
            "The user has exceeded the number of videos they may upload" in s
        )

    def _is_token_error(err: Exception) -> bool:
        s = str(err).lower()
        return (
            ("token" in s and "expired" in s) or
            ("invalid_grant" in s) or
            ("unauthorized_client" in s) or
            ("invalid_credentials" in s) or
            ("401" in s)
        )

    def _try_upload_with_fallbacks() -> bool:
        fb = os.getenv("UPLOAD_FALLBACKS", "").strip()
        fallbacks = [x.strip() for x in fb.split(",") if x.strip()]
        tried = []

        for acc in [account] + [a for a in fallbacks if a != account]:
            tried.append(acc)
            try:
                upload(
                    video_path=final_mp4, title=title, desc=desc, tags=tags,
                    privacy=yt_privacy, account=acc, thumbnail=thumb, default_lang=audio_lang
                )
                logging.info(f"[UPLOAD] âœ… success on account='{acc}'")
                return True
            except Exception as e:
                # ä¸Šé™ã‚¨ãƒ©ãƒ¼ãªã‚‰æ¬¡ã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¸
                if _is_limit_error(e):
                    logging.warning(f"[UPLOAD] âš ï¸ limit reached on account='{acc}' â†’ trying next fallback.")
                    continue

                # ãƒˆãƒ¼ã‚¯ãƒ³åˆ‡ã‚Œï¼ˆexpire/revokeï¼‰ãªã‚‰å³åœæ­¢ï¼‹é€šçŸ¥
                if _is_token_error(e):
                    logging.error(f"[UPLOAD] âŒ TOKEN ERROR on account='{acc}' â€” expired/revoked/unauthorized.")
                    try:
                        (TEMP / "TOKEN_EXPIRED.txt").write_text(
                            f"Token expired or revoked for account='{acc}'.\nDetail:\n{e}",
                            encoding="utf-8",
                        )
                    except Exception:
                        pass
                    raise SystemExit(f"[ABORT] Token expired/revoked for account='{acc}'. Please reauthorize.")

                # æƒ³å®šå¤–ã®ã‚¨ãƒ©ãƒ¼ã¯ raiseï¼ˆãƒã‚°æ¤œå‡ºç”¨ï¼‰
                logging.exception(f"[UPLOAD] unexpected error on account='{acc}'")
                raise

        # ã™ã¹ã¦ä¸Šé™ã‚¨ãƒ©ãƒ¼ â†’ ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã®ã‚³ãƒ³ãƒœã¸é€²è¡Œ
        msg = f"Upload skipped due to per-account limits. tried={tried}"
        logging.warning("[UPLOAD] " + msg)
        try:
            (TEMP / "UPLOAD_SKIPPED.txt").write_text(msg, encoding="utf-8")
        except Exception:
            pass
        return False

    _try_upload_with_fallbacks()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_all(topic, turns, privacy, do_upload, chunk_size):
    """
    è¦ªãƒ—ãƒ­ã‚»ã‚¹: å„ account ã”ã¨ã«å­ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•ï¼ˆISOLATED_RUN=1 ã‚’ä»˜ä¸ï¼‰
    å­ãƒ—ãƒ­ã‚»ã‚¹(ISOLATED_RUN=1): ãã®ã¾ã¾ run_one ã‚’å®Ÿè¡Œï¼ˆå†å¸°èµ·å‹•ã—ãªã„ï¼‰
    """
    isolated = os.getenv("ISOLATED_RUN", "0") == "1"

    if isolated:
        # ã“ã“ã¯å­ãƒ—ãƒ­ã‚»ã‚¹ç”¨ï¼šå¾“æ¥é€šã‚Šã«å®Ÿè¡Œï¼ˆTARGET_ONLY ãŒã‚ã‚Œã° 1 ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã¿ã«ãªã‚‹ï¼‰
        for combo in COMBOS:
            audio_lang  = combo["audio"]
            subs        = combo["subs"]
            account     = combo.get("account","default")
            title_lang  = _infer_title_lang(audio_lang, subs, combo)

            if TARGET_ONLY and account != TARGET_ONLY:
                continue

            picked_topic = topic
            context_hint = ""
            spec_for_run = None
            words_env_count = int(os.getenv("VOCAB_WORDS", "6"))

            if topic.strip().lower() == "auto":
                try:
                    picked_raw = pick_by_content_type("vocab", audio_lang, return_context=True)
                    picked_topic, context_hint, spec_for_run = _normalize_spec(
                        picked_raw, context_hint, audio_lang, words_env_count
                    )
                except TypeError:
                    picked_raw = pick_by_content_type("vocab", audio_lang)
                    picked_topic, context_hint, spec_for_run = _normalize_spec(
                        picked_raw, context_hint, audio_lang, words_env_count
                    )

            logging.info(f"[ISOLATED] {audio_lang} | subs={subs} | account={account} | theme={picked_topic}")
            run_one(
                picked_topic, turns, audio_lang, subs, title_lang,
                privacy, account, do_upload, chunk_size,
                context_hint=context_hint, spec=spec_for_run
            )
        return

    # ã“ã“ã¯è¦ªãƒ—ãƒ­ã‚»ã‚¹ï¼šå„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã”ã¨ã«å­ãƒ—ãƒ­ã‚»ã‚¹ã§ç‹¬ç«‹å®Ÿè¡Œ
    for combo in COMBOS:
        account = combo.get("account", "default")
        if TARGET_ONLY and account != TARGET_ONLY:
            continue

        cmd = [
            sys.executable, str(BASE / "main.py"),
            topic,
            "--privacy", privacy,
            "--chunk", str(chunk_size),
            "--account", account,
        ]
        if not do_upload:
            cmd.append("--no-upload")

        env = os.environ.copy()
        env["ISOLATED_RUN"] = "1"   # â† å­ãƒ—ãƒ­ã‚»ã‚¹å´ã§å†å¸°èµ·å‹•ã‚’æ­¢ã‚ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°

        logging.info(f"â–¶ Spawning isolated run for account={account}: {' '.join(cmd)}")
        subprocess.run(cmd, check=False, env=env)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
    ap = argparse.ArgumentParser()
    ap.add_argument("topic", help="èªå½™ãƒ†ãƒ¼ãƒã€‚AUTO ã§è‡ªå‹•é¸æŠã€‚ã‚«ãƒ³ãƒ/æ”¹è¡ŒåŒºåˆ‡ã‚Šãªã‚‰å˜èªãƒªã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨")
    ap.add_argument("--turns", type=int, default=8)  # äº’æ›ç”¨
    ap.add_argument("--privacy", default="unlisted", choices=["public","unlisted","private"])
    ap.add_argument("--lines-only", action="store_true")
    ap.add_argument("--no-upload", action="store_true")
    ap.add_argument("--chunk", type=int, default=9999, help="Shortsã¯åˆ†å‰²ã›ãš1æœ¬æ¨å¥¨")
    # â˜… è¿½åŠ : CLIã‹ã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’æŒ‡å®šã§ãã‚‹
    ap.add_argument("--account", type=str, default="", help="ã“ã® account ã®ã¿å®Ÿè¡Œï¼ˆcombos.yaml ã® account å€¤ã«ä¸€è‡´ï¼‰")
    args = ap.parse_args()

    # â”€â”€ Account ãƒ•ã‚£ãƒ«ã‚¿ã®æ±ºå®šï¼ˆCLI > ç’°å¢ƒå¤‰æ•°ï¼‰ â”€â”€
    target_cli = (args.account or "").strip()
    target_env = os.getenv("TARGET_ACCOUNT", "").strip()
    TARGET_ONLY = target_cli or target_env

    if TARGET_ONLY:
        selected = [c for c in COMBOS if c.get("account", "default") == TARGET_ONLY]
        if not selected:
            logging.error(f"[ABORT] No combos matched account='{TARGET_ONLY}'. Check combos.yaml.")
            raise SystemExit(2)
        # in-place ç½®æ›ï¼ˆä»–ã‹ã‚‰ã‚‚å‚ç…§ã•ã‚Œã‚‹ãŸã‚ï¼‰
        COMBOS[:] = selected
        logging.info(f"[ACCOUNT FILTER] Running only for account='{TARGET_ONLY}' ({len(COMBOS)} combo(s)).")

    topic = resolve_topic(args.topic)
    run_all(topic, args.turns, args.privacy, not args.no_upload, args.chunk)