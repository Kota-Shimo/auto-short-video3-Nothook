#!/usr/bin/env python
"""
main.py â€“ VOCABå°‚ç”¨ç‰ˆï¼ˆå˜ç´”çµåˆï¼‹æ—¥æœ¬èªãµã‚ŠãŒãª[TTSã®ã¿]å¯¾å¿œï¼‰

ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³:
  å˜èªãƒ†ãƒ¼ãƒï¼ˆAUTOâ†’topic_pickerï¼‰â†’ å˜èªãƒªã‚¹ãƒˆç”Ÿæˆ
  â†’ [å˜èªâ†’å˜èªâ†’ä¾‹æ–‡] ã‚’ç¹°ã‚Šè¿”ã—
  â†’ TTSï¼ˆæ—¥æœ¬èªã®ã€Œæ¼¢å­—ã ã‘å˜èªã€ã¯TTSç”¨ã«ãµã‚ŠãŒãªä»˜ä¸ï¼å­—å¹•ã¯åŸæ–‡ã®ã¾ã¾ï¼‰
  â†’ ï¼ˆç„¡éŸ³ã‚®ãƒ£ãƒƒãƒ—ã‚’æŒŸã‚“ã§ï¼‰å˜ç´”çµåˆã—ã¦ full.mp3
  â†’ lines.json â†’ chunk_builder.py â†’ ï¼ˆä»»æ„ï¼‰YouTubeã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

ç’°å¢ƒå¤‰æ•°:
- VOCAB_WORDS   : ç”Ÿæˆã™ã‚‹èªæ•° (æ—¢å®š: 6)
- DEBUG_SCRIPT  : "1" ã§å°æœ¬ãƒ»å­—å¹•ãƒ»å°ºã®ãƒ‡ãƒãƒƒã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ TEMP ã«å‡ºåŠ›
- GAP_MS        : ç™ºè©±é–“ã«æŒ¿å…¥ã™ã‚‹ç„¡éŸ³ï¼ˆãƒŸãƒªç§’, æ—¢å®š: 120ï¼‰
"""

import argparse, logging, re, json, subprocess, os
from datetime import datetime
from pathlib import Path
from shutil import rmtree

import yaml
from pydub import AudioSegment
from openai import OpenAI

from config         import BASE, OUTPUT, TEMP
from translate      import translate
from tts_openai     import speak
from audio_fx       import enhance
from bg_image       import fetch as fetch_bg
from thumbnail      import make_thumbnail
from upload_youtube import upload
from topic_picker   import pick_by_content_type

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GPT = OpenAI()
CONTENT_MODE = "vocab"      # å›ºå®š
DEBUG_SCRIPT = os.getenv("DEBUG_SCRIPT", "0") == "1"
GAP_MS       = int(os.getenv("GAP_MS", "120"))  # ç„¡éŸ³ã‚®ãƒ£ãƒƒãƒ—

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# combos.yaml èª­ã¿è¾¼ã¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with open(BASE / "combos.yaml", encoding="utf-8") as f:
    COMBOS = yaml.safe_load(f)["combos"]

def reset_temp():
    if TEMP.exists():
        rmtree(TEMP)
    TEMP.mkdir(exist_ok=True)

def sanitize_title(raw: str) -> str:
    # æ­£è¦è¡¨ç¾ãƒã‚°ä¿®æ­£: "\\s" â†’ "\s"
    title = re.sub(r"^\s*(?:\d+\s*[.)]|[-â€¢ãƒ»])\s*", "", raw)
    title = re.sub(r"[\s\u3000]+", " ", title).strip()
    return title[:97] + "â€¦" if len(title) > 100 else title or "Auto Video"

LANG_NAME = {
    "en": "English", "pt": "Portuguese", "id": "Indonesian",
    "ja": "Japanese","ko": "Korean", "es": "Spanish",
}

JP_CONV_LABEL = {
    "en": "è‹±ä¼šè©±", "ja": "æ—¥æœ¬èªä¼šè©±", "es": "ã‚¹ãƒšã‚¤ãƒ³èªä¼šè©±",
    "pt": "ãƒãƒ«ãƒˆã‚¬ãƒ«èªä¼šè©±", "ko": "éŸ“å›½èªä¼šè©±", "id": "ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢èªä¼šè©±",
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒˆãƒ”ãƒƒã‚¯å–å¾—: "AUTO"â†’ vocab ãƒ†ãƒ¼ãƒã‚’æ—¥æ›¿ã‚ã‚Šã§é¸ã¶
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def resolve_topic(arg_topic: str) -> str:
    if arg_topic and arg_topic.strip().lower() == "auto":
        first_audio_lang = COMBOS[0]["audio"]
        topic = pick_by_content_type("vocab", first_audio_lang)  # vocabãƒ†ãƒ¼ãƒ
        logging.info(f"[AUTO VOCAB THEME] {topic}")
        return topic
    return arg_topic

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# èªå½™ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _gen_example_sentence(word: str, lang_code: str) -> str:
    """ãã®å˜èªã‚’ä½¿ã£ãŸçŸ­ã„ä¾‹æ–‡ã‚’1ã¤ã ã‘ç”Ÿæˆï¼ˆå¤±æ•—æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    prompt = (
        f"Write one short, natural example sentence (<=12 words) in "
        f"{LANG_NAME.get(lang_code,'English')} using the word: {word}. "
        "No translation, no quotes."
    )
    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"user","content":prompt}],
            temperature=0.6,
        )
        sent = (rsp.choices[0].message.content or "").strip()
        return re.sub(r'^[\"â€œâ€\'\s]+|[\"â€œâ€\'\s]+$', '', sent)
    except Exception:
        return f"Let's practice the word {word} in a short sentence."

def _gen_vocab_list(theme: str, lang_code: str, n: int) -> list[str]:
    """ãƒ†ãƒ¼ãƒã‹ã‚‰ n èªã®å˜èªãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã€‚å¤±æ•—æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚"""
    theme_for_prompt = translate(theme, lang_code) if lang_code != "en" else theme
    prompt = (
        f"List {n} essential single or hyphenated words for {theme_for_prompt} context "
        f"in {LANG_NAME.get(lang_code,'English')}. Return ONLY one word per line, no numbering."
    )
    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"user","content":prompt}],
            temperature=0.5,
        )
        words = [w.strip() for w in (rsp.choices[0].message.content or "").splitlines() if w.strip()]
        cleaned = []
        for w in words:
            w = re.sub(r"^\d+[\).]?\s*", "", w)  # ç•ªå·é™¤å»
            if w and w not in cleaned:
                cleaned.append(w)
        if len(cleaned) >= n:
            return cleaned[:n]
    except Exception:
        pass
    fallback = ["check-in", "reservation", "checkout", "receipt", "elevator", "lobby", "upgrade"]
    return fallback[:n]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãµã‚ŠãŒãªï¼ˆæ—¥æœ¬èªTTSç”¨ãƒ»å­—å¹•ã«ã¯å‡ºã•ãªã„ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_KANJI_ONLY = re.compile(r"^[ä¸€-é¾¥ã€…]+$")

def _kana_reading(word: str) -> str:
    """æ¼¢å­—ã®ã¿ã®å˜èªã«å¯¾ã—ã¦ã²ã‚‰ãŒãªèª­ã¿ã‚’è¿”ã™ï¼ˆçŸ­ããƒ»è¨˜å·ãªã—ï¼‰"""
    try:
        rsp = GPT.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role":"user",
                "content":(
                    "æ¬¡ã®æ—¥æœ¬èªå˜èªã®èª­ã¿ã‚’ã²ã‚‰ãŒãªã ã‘ã§1èªè¿”ã—ã¦ãã ã•ã„ã€‚"
                    "è¨˜å·ãƒ»æ‹¬å¼§ãƒ»èª¬æ˜ã¯ä¸è¦ã€‚\n"
                    f"å˜èª: {word}"
                )
            }],
            temperature=0.0,
        )
        yomi = (rsp.choices[0].message.content or "").strip()
        yomi = re.sub(r"[^ã-ã‚–ã‚ã‚ãƒ¼]+", "", yomi)  # ã²ã‚‰ãŒãªã®ã¿
        return yomi[:20]
    except Exception:
        return ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¿ç”Ÿæˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_title(theme, title_lang: str, audio_lang_for_label: str | None = None):
    if title_lang == "ja":
        base = f"{theme} ã§ä½¿ãˆã‚‹ä¸€è¨€"
        label = JP_CONV_LABEL.get(audio_lang_for_label or "", "")
        t = f"{label} {base}" if label and label not in base else base
        return sanitize_title(t)[:28]
    else:
        t = f"{theme.capitalize()} vocab in one minute"
        return sanitize_title(t)[:55]

def make_desc(theme, title_lang: str):
    msg = {
        "ja": f"{theme} ã«å¿…é ˆã®èªå½™ã‚’çŸ­æ™‚é–“ã§ãƒã‚§ãƒƒã‚¯ã€‚å£°ã«å‡ºã—ã¦ä¸€ç·’ã«ç·´ç¿’ã—ã‚ˆã†ï¼ #vocab #learning",
        "en": f"Quick practice for {theme} vocabulary. Repeat after the audio! #vocab #learning",
        "pt": f"Pratique rÃ¡pido o vocabulÃ¡rio de {theme}. Repita em voz alta! #vocab #aprendizado",
        "es": f"PrÃ¡ctica rÃ¡pida de vocabulario de {theme}. Â¡Repite en voz alta! #vocab #aprendizaje",
        "ko": f"{theme} ì–´íœ˜ë¥¼ ë¹ ë¥´ê²Œ ì—°ìŠµí•˜ì„¸ìš”. ì†Œë¦¬ ë‚´ì–´ ë”°ë¼ ë§í•´ìš”! #vocab #learning",
        "id": f"Latihan cepat kosakata {theme}. Ucapkan keras-keras! #vocab #belajar",
    }
    return msg.get(title_lang, msg["en"])

def make_tags(theme, audio_lang, subs, title_lang):
    tags = [
        theme, "vocabulary", "language learning", "speaking practice",
        "listening practice", "subtitles"
    ]
    for code in subs:
        if code in LANG_NAME:
            tags.append(f"{LANG_NAME[code]} subtitles")
    seen, out = set(), []
    for t in tags:
        if t not in seen:
            seen.add(t); out.append(t)
    return out[:15]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å˜ç´”çµåˆï¼ˆãƒˆãƒªãƒŸãƒ³ã‚°ç„¡ã—ï¼‰ï¼šå„è¡Œã®é•·ã• + ã‚®ãƒ£ãƒƒãƒ—ã‚’ dur ã«æ¡ç”¨
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _concat_with_gaps(mp_paths, gap_ms=120):
    combined = AudioSegment.silent(duration=0)
    durs = []
    for idx, p in enumerate(mp_paths):
        seg = AudioSegment.from_file(p)
        seg_ms = len(seg)
        combined += seg
        extra = gap_ms if idx < len(mp_paths) - 1 else 0
        if extra:
            combined += AudioSegment.silent(duration=extra)
        durs.append((seg_ms + extra) / 1000.0)
    (TEMP / "full_raw.mp3").unlink(missing_ok=True)
    combined.export(TEMP / "full_raw.mp3", format="mp3")
    return durs

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1ã‚³ãƒ³ãƒœå‡¦ç†ï¼ˆvocab å°‚ç”¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_one(topic, turns, audio_lang, subs, title_lang, yt_privacy, account, do_upload, chunk_size):
    reset_temp()

    # topic ãŒã€Œå˜èªã®åˆ—ã€ãªã‚‰ãã®ã¾ã¾ä½¿ã†ã€‚ãã†ã§ãªã‘ã‚Œã° â€œãƒ†ãƒ¼ãƒâ€ ã¨ã¿ãªã—ã¦å˜èªç”Ÿæˆã€‚
    raw = (topic or "").replace("\r", "\n").strip()
    is_word_list = bool(re.search(r"[,;\n]", raw)) and len([w for w in re.split(r"[\n,;]+", raw) if w.strip()]) >= 2

    words_count = int(os.getenv("VOCAB_WORDS", "6"))
    if is_word_list:
        vocab_words = [w.strip() for w in re.split(r"[\n,;]+", raw) if w.strip()]
        theme = "custom list"
    else:
        theme = topic
        vocab_words = _gen_vocab_list(theme, audio_lang, words_count)

    # 1èªã‚ãŸã‚Š 3è¡Œãƒ–ãƒ­ãƒƒã‚¯: â‘ å˜èª â†’ â‘¡å˜èª â†’ â‘¢ä¾‹æ–‡
    dialogue = []
    for w in vocab_words:
        ex = _gen_example_sentence(w, audio_lang)
        dialogue.extend([("N", w), ("N", w), ("N", ex)])

    # éŸ³å£°ï¼†å­—å¹•ã®æº–å‚™
    valid_dialogue = [(spk, line) for (spk, line) in dialogue if line.strip()]
    mp_parts, sub_rows = [], [[] for _ in subs]

    # ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆï¼ˆå­—å¹•ç”¨ã®ç´ ï¼‰ã¯ä¿å­˜ã—ã¦ãŠã
    plain_lines = [line for (_, line) in valid_dialogue]

    for i, (spk, line) in enumerate(valid_dialogue, 1):
        # â”€â”€ TTSç”¨ãƒ†ã‚­ã‚¹ãƒˆæœ€çµ‚åŒ–ï¼ˆæ—¥æœ¬èªãƒ»æ¼¢å­—ã®ã¿ã®â€œå˜èªâ€ã«èª­ã¿ã‚’ä»˜ä¸ï¼‰â”€â”€
        tts_line = line
        if audio_lang == "ja" and _KANJI_ONLY.fullmatch(line):
            yomi = _kana_reading(line)
            if yomi:
                tts_line = f"{line}"  # éŸ³å£°ã¯èª­ã¿ã‚’å¼·åˆ¶ã€å­—å¹•ã¯åŸæ–‡ã®ã¾ã¾

        # éŸ³å£°åˆæˆ
        mp = TEMP / f"{i:02d}.mp3"
        speak(audio_lang, spk, tts_line, mp, style="neutral")
        mp_parts.append(mp)

        # å­—å¹•ï¼ˆéŸ³å£°è¨€èª=åŸæ–‡ã€ä»–è¨€èª=ç¿»è¨³ï¼‰â€»ãµã‚ŠãŒãªã¯å…¥ã‚Œãªã„
        for r, lang in enumerate(subs):
            sub_rows[r].append(line if lang == audio_lang else translate(line, lang))

    # å˜ç´”çµåˆï¼ˆç„¡éŸ³ã‚®ãƒ£ãƒƒãƒ—æŒ¿å…¥ã€ãƒˆãƒªãƒ ç„¡ã—ï¼‰
    new_durs = _concat_with_gaps(mp_parts, gap_ms=GAP_MS)
    enhance(TEMP/"full_raw.mp3", TEMP/"full.mp3")

    # èƒŒæ™¯ï¼šæœ€åˆã®å˜èªã‚’ä½¿ã†
    bg_png = TEMP / "bg.png"
    first_word = valid_dialogue[0][1] if valid_dialogue else theme
    fetch_bg(first_word, bg_png)

    # lines.jsonï¼ˆ[spk, sub1, sub2, ..., dur]ï¼‰
    lines_data = []
    for i, ((spk, txt), dur) in enumerate(zip(valid_dialogue, new_durs)):
        row = [spk]
        for r in range(len(subs)):
            row.append(sub_rows[r][i])
        row.append(dur)
        lines_data.append(row)
    (TEMP/"lines.json").write_text(json.dumps(lines_data, ensure_ascii=False, indent=2), encoding="utf-8")

    # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
    if DEBUG_SCRIPT:
        try:
            (TEMP / "script_raw.txt").write_text("\n".join(plain_lines), encoding="utf-8")
            with open(TEMP / "subs_table.tsv", "w", encoding="utf-8") as f:
                header = ["idx", "text"] + [f"sub:{code}" for code in subs]
                f.write("\t".join(header) + "\n")
                for idx in range(len(valid_dialogue)):
                    row = [str(idx+1), valid_dialogue[idx][1]] + [sub_rows[r][idx] for r in range(len(subs))]
                    f.write("\t".join(row) + "\n")
            with open(TEMP / "durations.txt", "w", encoding="utf-8") as f:
                total = 0.0
                for i, d in enumerate(new_durs, 1):
                    total += d
                    f.write(f"{i:02d}\t{d:.3f}s\n")
                f.write(f"TOTAL\t{total:.3f}s\n")
        except Exception as e:
            logging.warning(f"[DEBUG_SCRIPT] write failed: {e}")

    if args.lines_only:
        return

    # ã‚µãƒ ãƒ
    thumb = TEMP / "thumbnail.jpg"
    thumb_lang = subs[1] if len(subs) > 1 else audio_lang
    make_thumbnail(theme, thumb_lang, thumb)

    # å‹•ç”»ç”Ÿæˆ
    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    final_mp4 = OUTPUT / f"{audio_lang}-{'_'.join(subs)}_{stamp}.mp4"
    final_mp4.parent.mkdir(parents=True, exist_ok=True)

    cmd = [
        "python", str(BASE/"chunk_builder.py"),
        str(TEMP/"lines.json"), str(TEMP/"full.mp3"), str(bg_png),
        "--chunk", str(chunk_size),
        "--rows", str(len(subs)),
        "--out", str(final_mp4),
    ]
    logging.info("ğŸ”¹ chunk_builder cmd: %s", " ".join(cmd))
    subprocess.run(cmd, check=True)

    if not do_upload:
        return

    # ãƒ¡ã‚¿ç”Ÿæˆï¼†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    title = make_title(theme, title_lang, audio_lang_for_label=audio_lang)
    desc  = make_desc(theme, title_lang)
    tags  = make_tags(theme, audio_lang, subs, title_lang)

    upload(video_path=final_mp4, title=title, desc=desc, tags=tags,
           privacy=yt_privacy, account=account, thumbnail=thumb, default_lang=audio_lang)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_all(topic, turns, privacy, do_upload, chunk_size):
    for combo in COMBOS:
        audio_lang  = combo["audio"]
        subs        = combo["subs"]
        account     = combo.get("account","default")
        title_lang  = combo.get("title_lang", subs[1] if len(subs)>1 else audio_lang)
        logging.info(f"=== Combo: {audio_lang}, subs={subs}, account={account}, title_lang={title_lang}, mode={CONTENT_MODE} ===")

        picked_topic = topic
        if topic.strip().lower() == "auto":
            picked_topic = pick_by_content_type("vocab", audio_lang)
            logging.info(f"[{audio_lang}] picked vocab theme: {picked_topic}")

        run_one(picked_topic, turns, audio_lang, subs, title_lang, privacy, account, do_upload, chunk_size)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
    ap = argparse.ArgumentParser()
    ap.add_argument("topic", help='èªå½™ãƒ†ãƒ¼ãƒã€‚AUTO ã§è‡ªå‹•é¸æŠã€‚ã‚«ãƒ³ãƒ/æ”¹è¡ŒåŒºåˆ‡ã‚Šãªã‚‰å˜èªãƒªã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨')
    ap.add_argument("--turns", type=int, default=8)  # æœªä½¿ç”¨ï¼ˆäº’æ›ç”¨ï¼‰
    ap.add_argument("--privacy", default="unlisted", choices=["public","unlisted","private"])
    ap.add_argument("--lines-only", action="store_true")
    ap.add_argument("--no-upload", action="store_true")
    ap.add_argument("--chunk", type=int, default=9999, help="Shortsã¯åˆ†å‰²ã›ãš1æœ¬æ¨å¥¨")
    args = ap.parse_args()

    topic = resolve_topic(args.topic)
    run_all(topic, args.turns, args.privacy, not args.no_upload, args.chunk)